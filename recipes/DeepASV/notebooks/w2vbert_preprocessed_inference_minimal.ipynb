{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458cabd1",
   "metadata": {},
   "source": [
    "# Minimal: Preprocessed TorchScript Inference\n",
    "\n",
    "This notebook shows the minimal steps to compute a speaker embedding using the preprocessed TorchScript artifact and the saved Hugging Face feature-extractor. It expects the export artifacts to be under `packages/w2vbert_speaker/artifacts/` (created by `scripts/export_w2vbert_torchscript.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8baaa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zb/NWG/w2v-BERT-2.0_SV/.venv_w2vbert_notebook/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['W2VBERT_SPK_Module',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'audio_encoder',\n",
       " 'compute_input_features_from_wave',\n",
       " 'feature_utils',\n",
       " 'forward_impl',\n",
       " 'load_feature_extractor',\n",
       " 'local',\n",
       " 'module']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import w2vbert_speaker\n",
    "dir(w2vbert_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fccb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/zb/NWG/w2v-BERT-2.0_SV/.venv_w2vbert_notebook/bin/python\n",
      "w2vbert_speaker import: OK\n"
     ]
    }
   ],
   "source": [
    "# Quick environment & import check (run this first).\n",
    "import sys\n",
    "print('Python executable:', sys.executable)\n",
    "try:\n",
    "    # ensure package exports are available in this kernel\n",
    "    from w2vbert_speaker import load_feature_extractor, compute_input_features_from_wave\n",
    "    print('w2vbert_speaker import: OK')\n",
    "except Exception as exc:\n",
    "    import traceback\n",
    "    print('Failed to import w2vbert_speaker in this kernel.')\n",
    "    traceback.print_exc()\n",
    "    raise RuntimeError(\n",
    "        'Please install the package into the kernel environment (e.g. `pip install -e packages/w2vbert_speaker`) and restart the kernel.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ab1ac",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- A Python environment with `torch`, `transformers`, `soundfile`, and `librosa` (or `torchaudio`) installed.\n",
    "- The exported artifacts: `w2vbert_speaker_script_preprocessed.pt` and the `feature_extractor/` folder under `packages/w2vbert_speaker/artifacts/`.\n",
    "- If you used the repository helper, run `./scripts/run_export_preprocessed.sh` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0f113f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Adjust these paths if your repo layout differs\u001b[39;00m\n\u001b[32m      7\u001b[39m REPO_ROOT = Path.cwd()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "# Adjust these paths if your repo layout differs\n",
    "REPO_ROOT = Path.cwd()\n",
    "ARTIFACTS = (REPO_ROOT / 'packages' / 'w2vbert_speaker' / 'artifacts').resolve()\n",
    "SCRIPTED_PREPROCESSED = ARTIFACTS / 'w2vbert_speaker_script_preprocessed.pt'\n",
    "FEATURE_EXTRACTOR_DIR = ARTIFACTS / 'feature_extractor'\n",
    "\n",
    "# Example audio (change if not available)\n",
    "AUDIO_PATH = (REPO_ROOT / '..' / 'datasets' / 'voxceleb1test' / 'wav' / 'id10270' / '5r0dWxy17C8' / '00001.wav').resolve()\n",
    "print('artifact preprocessed exists:', SCRIPTED_PREPROCESSED.exists())\n",
    "print('feature_extractor dir exists:', FEATURE_EXTRACTOR_DIR.exists())\n",
    "print('audio exists:', AUDIO_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4061a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved feature extractor and compute input_features (minimal runtime)\n",
    "# Import the helpers from the installed package (package must be installed in the kernel's env)\n",
    "from w2vbert_speaker import load_feature_extractor, compute_input_features_from_wave\n",
    "\n",
    "if not FEATURE_EXTRACTOR_DIR.exists():\n",
    "    raise FileNotFoundError(f'Feature extractor not found at {FEATURE_EXTRACTOR_DIR}; run the export script to create it.')\n",
    "\n",
    "feature_extractor = load_feature_extractor(FEATURE_EXTRACTOR_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and (if necessary) resample audio to the extractor's sampling rate\n",
    "wave, sr = sf.read(str(AUDIO_PATH), dtype='float32')\n",
    "# convert to mono if necessary\n",
    "if wave.ndim > 1:\n",
    "    wave = wave.mean(axis=1)\n",
    "target_sr = int(feature_extractor.sampling_rate)\n",
    "if sr != target_sr:\n",
    "    wave = librosa.resample(wave, orig_sr=sr, target_sr=target_sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_w2vbert_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
